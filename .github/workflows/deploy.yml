name: Scrape & Deploy to Surge

on:
  workflow_dispatch:            # manual Run button
  push:
    branches: [ main ]          # on pushes to main
  schedule:
    - cron: "0 */6 * * *"       # every 6h UTC

jobs:
  deploy:
    runs-on: ubuntu-latest
    env:
      DOMAIN: dmhshows.surge.sh     # <-- your Surge domain
      DEPLOY_DIR: ./public

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Show repo layout
        run: |
          echo "PWD=$PWD"
          ls -la
          echo "---- public ----"
          ls -la public || true

      - name: Install scraper deps (Playwright + Chromium)
        run: |
          npm ci || npm i
          npx playwright install --with-deps chromium

      - name: Run scraper (writes public/dmh-events.json)
        run: npm run scrape

      - name: Upload debug (HTML + screenshot)
        uses: actions/upload-artifact@v4
        with:
          name: listing-debug
          path: public/debug/**           # grabs all pages' debug files
          if-no-files-found: ignore

      - name: Verify build output
        run: |
          test -f "$DEPLOY_DIR/index.html" || (echo "::error::index.html missing in $DEPLOY_DIR" && exit 1)
          if [ ! -f "$DEPLOY_DIR/dmh-events.json" ]; then
            echo "::warning::dmh-events.json missing; scraper may have produced no events"
          fi

      - name: Install Surge CLI
        run: npm i -g surge

      - name: Deploy to Surge
        env:
          SURGE_LOGIN: ${{ secrets.SURGE_LOGIN }}
          SURGE_TOKEN: ${{ secrets.SURGE_TOKEN }}
        run: |
          echo "Deploying $DEPLOY_DIR -> https://$DOMAIN"
          npx surge "$DEPLOY_DIR" "$DOMAIN" --token "$SURGE_TOKEN"
